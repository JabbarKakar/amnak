import 'dart:async';

import 'package:agora_rtc_engine/agora_rtc_engine.dart';
import 'package:amnak/core/view/widgets/language_direction.dart';
import 'package:amnak/export.dart';
import 'package:permission_handler/permission_handler.dart';

class WalkiPage extends StatefulWidget {
  const WalkiPage({super.key, required this.channel, required this.token});
  final String token;
  final String channel;

  @override
  State<WalkiPage> createState() => _WalkiPageState();
}

// Application state class
class _WalkiPageState extends State<WalkiPage> {
  late RtcEngine _engine;

  @override
  void initState() {
    super.initState();
    initAgora();
  }

  // Initialize
  Future<void> initAgora() async {
    Logger().i(widget.channel);
    Logger().i(widget.token);
    // Get permission
    await [Permission.microphone].request();

    // Create an RtcEngine instance
    _engine = await createAgoraRtcEngine();

    // Initialize RtcEngine and set the channel profile
    await _engine.initialize(const RtcEngineContext(
      appId: appId,
      channelProfile: ChannelProfileType.channelProfileCommunication,
    ));

    // Handle engine events
    _engine.registerEventHandler(
      RtcEngineEventHandler(
        onJoinChannelSuccess: (RtcConnection connection, int elapsed) {
          Logger().i('local user ${connection.localUid} joined');
          setState(() {});
        },
        onError: (err, msg) => Logger().e('onError: $err, $msg'),
        onUserJoined:
            (RtcConnection connection, int remoteUid, int elapsed) async {
          Logger().i("remote user $remoteUid joined");
          setState(() {});
          await _engine.setEnableSpeakerphone(true);
          await _engine.muteLocalAudioStream(true);
        },
        onUserOffline: (RtcConnection connection, int remoteUid,
            UserOfflineReasonType reason) {
          Logger().i("remote user $remoteUid left channel");
          setState(() {});
        },
      ),
    );

    // Join a channel using a temporary token and channel name
    await _engine.joinChannel(
      token: widget.token,
      channelId: widget.channel,
      options: const ChannelMediaOptions(
          // Automatically subscribe to all audio streams
          autoSubscribeAudio: true,
          // Publish microphone audio
          publishMicrophoneTrack: true,
          // Set user role to clientRoleBroadcaster (broadcaster) or clientRoleAudience (audience)
          clientRoleType: ClientRoleType.clientRoleBroadcaster),
      uid:
          0, // When you set uid to 0, a user name is randomly generated by the engine
    );
  }

  @override
  void dispose() {
    super.dispose();
    _dispose();
  }

  Future<void> _dispose() async {
    await _engine.leaveChannel(); // Leave the channel
    await _engine.release(); // Release resources
  }

  bool _isSpeaking = false;

  Future<void> _muteMic() async {
    await _engine.muteLocalAudioStream(true);
    setState(() => _isSpeaking = false);
  }

  Future<void> _unmuteMic() async {
    await _engine.muteLocalAudioStream(false);
    setState(() => _isSpeaking = true);
  }

  @override
  Widget build(BuildContext context) {
    return LanguageDirection(
      child: Scaffold(
        appBar: const CustomAppBar(),
        body: Center(
          child: GestureDetector(
            onTapDown: (_) => _unmuteMic(),
            onTapUp: (_) => _muteMic(),
            onTapCancel: () => _muteMic(),
            child: Container(
              width: 100,
              height: 100,
              decoration: BoxDecoration(
                color: _isSpeaking ? Colors.redAccent : Colors.blueAccent,
                shape: BoxShape.circle,
              ),
              child: const Icon(
                Icons.mic,
                color: Colors.white,
                size: 40,
              ),
            ),
          ),
        ),
      ),
    );
  }
}
